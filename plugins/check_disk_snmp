#! /usr/bin/python

import re
import numpy
import yaml
import time
import argparse, sys, time
from pysnmp.entity.rfc3413.oneliner import cmdgen
from decimal import *

args_list = None
varBinds = None
per_month = 31
per_ten = 10
per_two = 2

hrstorage_oid = '1.3.6.1.2.1.25.2.3.1'
hrstorage_type_oid = '1.3.6.1.2.1.25.2.3.1.2'
hrstorage_label_oid = '1.3.6.1.2.1.25.2.3.1.3'
hrstorage_alloc_oid = '1.3.6.1.2.1.25.2.3.1.4'
hrstorage_size_oid = '1.3.6.1.2.1.25.2.3.1.5'
hrstorage_used_oid = '1.3.6.1.2.1.25.2.3.1.6'

hrstorage_type_fixeddisk = '1.3.6.1.2.1.25.2.1.4'

disk_indexes = []
disk_label = []
disk_alloc_units = []
disk_stor_size = []
disk_stor_used = []
disk_used_percent = []

SUCCESS = 0
WARNING = 1
CRITICAL = 2
UNKNOWN = 3

exit_str = [ "OK", "Warning", "Critical", "Unknown" ]

parser = argparse.ArgumentParser(description="Description to be add later")
parser.add_argument('-t', '--host', required=True, help='host name/address which is used to do snmpwalk')
parser.add_argument('-n', '--hostname', help='host name')
parser.add_argument('-s', '--comstr', required=True, help='community string')
parser.add_argument('-w', '--warning', type=int, help='warning')
parser.add_argument('-c', '--critical', type=int, help='critical')
parser.add_argument('-f', '--file', required=True, help='File to to store the disk information')
parser.add_argument('-d', '--exclude', help='Excluding the drive')
parser.add_argument('-y', '--min', nargs='?', type=int, default=1, help='Minimum time span between the oldest and newest datapoint which permits calculation of the growth ratio.')
parser.add_argument('-x', '--max', nargs='?', type=int, default=360, help='Maximum time span between the oldest and newest datapoints. Points older that this are removed and are no longer taken into consideration.')

class HistoryFile():

   _data = {}
   _location = None
   _max_averaging_window = None
   _min_averaging_window = None

   @classmethod
   def remove_old_datapoints(cls):
      cur_time = time.time()
      averaging_border = cur_time - cls._max_averaging_window * 3600 * 24 
      for mountpoint in cls._data['datapoints']['disk'].keys():
         cur_dict = cls._data['datapoints']['disk'][mountpoint]['space']
         cls._data['datapoints']['disk'][mountpoint]['space'] = \
            dict((x, cur_dict[x]) for x in cur_dict.keys()
               if x > averaging_border)
   @classmethod
   def init(cls, location, max_averaging_window, min_averaging_window, hostname):
      cls._max_averaging_window = max_averaging_window
      cls._min_averaging_window = min_averaging_window
      cls._location = location
      
      try:
         with open(location, 'r') as fh:
            cls._data = yaml.safe_load(fh)
      except (IOError, yaml.YAMLError):
         cls._data = {'datapoints': { 'disk': {}, 'host': hostname}}
      else:
         cls._data['datapoints']['host'] = hostname
         cls.remove_old_datapoints()
         for d in cls._data['datapoints']['disk'].keys():
            _space = cls._data['datapoints']['disk'][d]['space']
            cls._data['datapoints']['disk'][d] = dict()
            cls._data['datapoints']['disk'][d]['space'] = _space
   @classmethod
   def add_datapoint(cls, d_used=None, d_total=None, d_used_p=None, path=None):
      float(d_used)

      cur_time = round(time.time())
      if path not in cls._data['datapoints']['disk'].keys():
         cls._data['datapoints']['disk'][path] = dict()
         cls._data['datapoints']['disk'][path]['space'] = dict()

      cls._data['datapoints']['disk'][path]['space'][cur_time] = d_used
      cls._data['datapoints']['disk'][path]['total'] = d_total
      cls._data['datapoints']['disk'][path]['util'] = d_used_p + " %"
	
   @classmethod
   def add_diskstat(cls, d_stat=None, path=None):
      cls._data['datapoints']['disk'][path]['growstat'] = format(d_stat['d_grow_rate'], ".2f") + " Mb/day"
      cls._data['datapoints']['disk'][path]['growstatp'] = format(d_stat['d_grow_day_p'], ".2f") + " %"
      cls._data['datapoints']['disk'][path]['growstatp80'] = d_stat['d_grow_80_p']
      cls._data['datapoints']['disk'][path]['growstatp90'] = d_stat['d_grow_90_p']
      cls._data['datapoints']['disk'][path]['growstatp100'] = d_stat['d_grow_100_p']

   @classmethod
   def add_diskstat_2d(cls, d_stat=None, path=None):
      cls._data['datapoints']['disk'][path]['growstat2d'] = format(d_stat['d_grow_rate'], ".2f") + " Mb/day"
      cls._data['datapoints']['disk'][path]['growstat2dp'] = format(d_stat['d_grow_day_p'], ".2f") + " %"
      cls._data['datapoints']['disk'][path]['growstat2dp80'] = d_stat['d_grow_80_p']
      cls._data['datapoints']['disk'][path]['growstat2dp90'] = d_stat['d_grow_90_p']
      cls._data['datapoints']['disk'][path]['growstat2dp100'] = d_stat['d_grow_100_p']

   @classmethod
   def add_diskstat_10d(cls, d_stat=None, path=None):
      cls._data['datapoints']['disk'][path]['growstat10d'] = format(d_stat['d_grow_rate'], ".2f") + " Mb/day"
      cls._data['datapoints']['disk'][path]['growstat10dp'] = format(d_stat['d_grow_day_p'], ".2f") + " %"
      cls._data['datapoints']['disk'][path]['growstat10dp80'] = d_stat['d_grow_80_p']
      cls._data['datapoints']['disk'][path]['growstat10dp90'] = d_stat['d_grow_90_p']
      cls._data['datapoints']['disk'][path]['growstat10dp100'] = d_stat['d_grow_100_p']

   @classmethod
   def add_diskstat_1m(cls, d_stat=None, path=None):
      cls._data['datapoints']['disk'][path]['growstat1m'] = format(d_stat['d_grow_rate'], ".2f") + " Mb/day"
      cls._data['datapoints']['disk'][path]['growstat1mp'] = format(d_stat['d_grow_day_p'], ".2f") + " %"
      cls._data['datapoints']['disk'][path]['growstat1mp80'] = d_stat['d_grow_80_p']
      cls._data['datapoints']['disk'][path]['growstat1mp90'] = d_stat['d_grow_90_p']
      cls._data['datapoints']['disk'][path]['growstat1mp100'] = d_stat['d_grow_100_p']

   @classmethod
   def verify_dataspan(cls, path=None, min_w=None):
      dataspan = cls.get_dataspan(path)
      if min_w==None:
        min_w=cls._min_averaging_window
      return (dataspan - min_w)

   @classmethod
   def get_dataspan(cls, path=None):
      timestamps = cls._data['datapoints']['disk'][path]['space'].keys()
      dataspan = round((max(timestamps) - min(timestamps))/(3600*24), 2)
      return dataspan

   @classmethod
   def get_datapoints(cls, path=None):
      cls.remove_old_datapoints()
      datapoints = cls._data['datapoints']['disk'][path]['space']
      return datapoints

   @classmethod
   def get_customdatapoints(cls, path=None, days=None):
      cls.remove_old_datapoints()
      cur_time = time.time()
      averaging_border = cur_time - days * 3600 * 24
      cur_dict = cls._data['datapoints']['disk'][path]['space'] 
      result_dict = \
      dict((x, cur_dict[x]) for x in cur_dict.keys()        
        if x > averaging_border)
      return result_dict  
   
   @classmethod
   def excluding_drives(cls, ex_drive=None):
      if(ex_drive in cls._data['datapoints']['disk']):
         del cls._data['datapoints']['disk'][ex_drive]

   @classmethod
   def check_drives(cls, all_disk_l=None):
      for d_label in cls._data['datapoints']['disk'].keys():
         if d_label not in all_disk_l:
            del cls._data['datapoints']['disk'][d_label]
 
   @classmethod
   def save(cls):
      cls.remove_old_datapoints()
      with open(cls._location, 'w') as fh:
         data = yaml.dump(cls._data, default_flow_style=False) 
         fh.write(data)

def find_current_grow_ratio(datapoints):
   sorted_x = sorted(datapoints.keys())
   y = numpy.array([datapoints[x] for x in sorted_x])
   x = numpy.array(sorted_x)

   A = numpy.vstack([x, numpy.ones(len(x))]).T

   #m, c = numpy.linalg.lstsq(A, y)[0]

   slope, intercept = numpy.linalg.lstsq(A, y)[0]

   return round(slope*3600*24, 2)

def find_disk_usage(d_used=None, d_total=None):
   d_used_percent = d_used*100/d_total
   return format(d_used_percent, ".2f")

def find_current_stat(d_used=None, d_total=None, d_grow_rate=None,):
   dstat = dict()
   dstat['d_grow_rate'] = d_grow_rate

   d_free = d_total-d_used
   dstat['d_grow_day_p'] = d_grow_rate*100/d_total
   
   if d_grow_rate == float(0) and d_free != float(0):
      dstat['d_grow_80_p'] = None
      dstat['d_grow_90_p'] = None
      dstat['d_grow_100_p'] = None
   elif d_free == float(0):
      dstat['d_grow_80_p'] = 0
      dstat['d_grow_90_p'] = 0
      dstat['d_grow_100_p'] = 0
   else:
      dstat['d_grow_80_p'] = int((d_free/d_grow_rate)*80/100)
      dstat['d_grow_90_p'] = int((d_free/d_grow_rate)*90/100)
      dstat['d_grow_100_p'] = int(d_free/d_grow_rate)
   return dstat
   

def parse_args(args):

   global args_list
   args.pop(0)
   args_list = parser.parse_args(args)
   if args_list.warning==0 or args_list.critical==0 or args_list.min==0 or args_list.max==0:
      print "Value should be greater than 0."
      exit(3)
   elif args_list.warning >= args_list.critical:
      print "Error: Critical value should be greater than Warning"
      exit(3)
   elif args_list.min >= args_list.max:
      print "Error: Max value should be greater than Min"
      exit(3)
   elif args_list.max <= per_month:
      print "Error: Max value should be greater than 31"
      exit(3)

def output(exitcode, msg, perfdata=None):
   output_str = "RESPONSE: " + exit_str[exitcode] + " - " + msg
   if perfdata != None:
      output_str = output_str + ("|%s" % (perfdata))
   print output_str
   exit(exitcode)

def get_snmp_disk():
   global varBinds
   cmdGen = cmdgen.CommandGenerator()
   try:
      errorIndication, errorStatus, errorIndex, varBinds = cmdGen.nextCmd(
          cmdgen.CommunityData(args_list.comstr),
          cmdgen.UdpTransportTarget((args_list.host,161)),
          hrstorage_oid
      )
   except Exception, err:
      error_str = "Unexpected error %s" % (err)
      output(UNKNOWN, error_str)
   if errorIndication:
      output(UNKNOWN, "Error "+str(errorIndication))
   else:
      if errorStatus:
         error = ('Error %s at %s' % (
             errorStatus.prettyPrint(),
             errorIndex and varBindTable[-1][int(errorIndex)-1] or '?'
             )
         )
         output(UNKNOWN, error)
      else:
         for varBindTableRow in varBinds:
            for name, val in varBindTableRow:
               if(re.match(hrstorage_type_oid, str(name)) and hrstorage_type_fixeddisk==str(val)):
                  disk_indexes.append(re.search('\.([0-9]+)$', str(name)).group(1))

def find_and_store_disk():
   for  varBindTableRow in varBinds:
      for  name, val in varBindTableRow: 
         if re.match(hrstorage_label_oid, str(name)):
            d_index = re.search('\.([0-9]+)$', str(name)).group(1)
            if d_index in disk_indexes:
               disk_label.append(str(val).split()[0])
         elif re.match(hrstorage_alloc_oid, str(name)):
            d_index = re.search('\.([0-9]+)$', str(name)).group(1)
            if d_index in disk_indexes:
               disk_alloc_units.append(str(val))
         elif re.match(hrstorage_size_oid, str(name)):
            d_index = re.search('\.([0-9]+)$', str(name)).group(1)
            if d_index in disk_indexes:
               disk_stor_size.append(str(val))
         elif re.match(hrstorage_used_oid, str(name)):
            d_index = re.search('\.([0-9]+)$', str(name)).group(1)
            if d_index in disk_indexes:
               disk_stor_used.append(str(val))

def find_disk_percent():
   global disk_used_percent
   disk_used = numpy.array(map(long, disk_stor_used))
   disk_size = numpy.array(map(long, disk_stor_size))
   disk_used_percent = disk_used * 100 / disk_size


def main():

   numpy.seterr(divide = 'ignore')
   parse_args(sys.argv)
   msg = ""
   no_data = []
   data = {}
 
   if(args_list.hostname):
      host_name=args_list.hostname
   else:
      host_name=args_list.host

   HistoryFile.init(location=args_list.file, max_averaging_window=args_list.max, min_averaging_window=args_list.min, hostname=host_name)

   get_snmp_disk()
   find_and_store_disk()
   #find_disk_percent()

   if(args_list.exclude): 
      exclude_drive=args_list.exclude.split(",")
      for drive in exclude_drive:
         HistoryFile.excluding_drives(ex_drive=drive)
   
   HistoryFile.check_drives(all_disk_l=disk_label)

   for i, disk_index in enumerate(disk_indexes):
      disk_used = round(int(disk_alloc_units[i]) * int(disk_stor_used[i])/1024**2, 2)      
      disk_total = round(int(disk_alloc_units[i]) * int(disk_stor_size[i])/1024**2, 2)
      disk_l = disk_label[i]

      if args_list.exclude and disk_l in exclude_drive:
          continue 

      float(disk_used)
      float(disk_total)
      if disk_total == 0.0:
          continue

      disk_free = disk_total - disk_used

      disk_used_percent = find_disk_usage(d_used=disk_used, d_total=disk_total)

      HistoryFile.add_datapoint(d_used=disk_used, d_total=disk_total, d_used_p=disk_used_percent, path=disk_l)

      tmp = HistoryFile.verify_dataspan(path=disk_l)
      if tmp < 0:
         no_data.append(disk_l)
      else:
         datapoints = HistoryFile.get_datapoints(path=disk_l)
         current_growth = find_current_grow_ratio(datapoints)
         float(current_growth)
         disk_stat = find_current_stat(d_used=disk_used, d_total=disk_total, d_grow_rate=current_growth)
         HistoryFile.add_diskstat(d_stat=disk_stat, path=disk_l)

         data[disk_l] = []
         data[disk_l].append(current_growth)
         data[disk_l].append(disk_used_percent)
         data[disk_l].append(disk_free)
         data[disk_l].append(disk_stat['d_grow_80_p'])
         data[disk_l].append(disk_stat['d_grow_90_p'])

         tmp2d = HistoryFile.verify_dataspan(path=disk_l, min_w=per_two)
         if tmp2d >=0:
            datapoints = HistoryFile.get_customdatapoints(path=disk_l, days=per_two)
            current_growth = find_current_grow_ratio(datapoints)
            float(current_growth)
            disk_stat = find_current_stat(d_used=disk_used, d_total=disk_total, d_grow_rate=current_growth)
            HistoryFile.add_diskstat_2d(d_stat=disk_stat, path=disk_l)
        
            tmp10d = HistoryFile.verify_dataspan(path=disk_l, min_w=per_ten)
            if tmp10d >=0:
               datapoints = HistoryFile.get_customdatapoints(path=disk_l, days=per_ten)
               current_growth = find_current_grow_ratio(datapoints)
               float(current_growth)
               disk_stat = find_current_stat(d_used=disk_used, d_total=disk_total, d_grow_rate=current_growth)
               HistoryFile.add_diskstat_10d(d_stat=disk_stat, path=disk_l)

               tmp1m = HistoryFile.verify_dataspan(path=disk_l, min_w=per_month)
               if tmp1m >=0:
                  datapoints = HistoryFile.get_customdatapoints(path=disk_l, days=per_month)
                  current_growth = find_current_grow_ratio(datapoints)
                  float(current_growth)
                  disk_stat = find_current_stat(d_used=disk_used, d_total=disk_total, d_grow_rate=current_growth)
                  HistoryFile.add_diskstat_1m(d_stat=disk_stat, path=disk_l)

   for d in data.keys():
      if msg == "" :
         msg = d + ": " + str(data[d][0]) + " Mb/day"
      else:
         msg = msg + ", " + d + ": " + str(data[d][0]) + " Mb/day"

   if no_data:
      if msg == "" :
         msg = "Not enough data to calculate for disks " + ", ".join(no_data)
      else:
         msg = msg + ", Not enough data to calculate for disks " + ", ".join(no_data)

   HistoryFile.save()

   output(SUCCESS, msg)

if __name__ == "__main__":
   main()
